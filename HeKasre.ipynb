{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297406ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from hekasre_datamodule import HeKasreDataModule\n",
    "from hekasre_model import HeKasreGruModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a050ebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/core/datamodule.py:74: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n",
      "  \"DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\"\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "data_module = HeKasreDataModule(\n",
    "    train_path=Path(\"./data/batch_01/train.json\"),\n",
    "    val_path=Path(\"./data/batch_01/val.json\"),\n",
    "    test_path=Path(\"./data/batch_01/test.json\"),\n",
    "    fasttext_path=Path(\"./cc.fa.300.bin\"),\n",
    "    mode=\"pack\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c0a4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "673"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_module.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f160176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_module.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc379ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_module.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54007a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeKasreGruModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdf09fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_f1\", patience=20, mode=\"max\")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"{epoch}-{val_loss:.2f}-{val_f1:.2f}\",\n",
    "    monitor=\"val_f1\",\n",
    "    mode=\"max\",\n",
    "    save_top_k=5,\n",
    "    save_last=True,\n",
    "    every_n_epochs=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    auto_lr_find=True,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11ca0db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:112: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/data.py:60: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  \"Trying to infer the `batch_size` from an ambiguous collection. The batch size we\"\n",
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:112: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:408: UserWarning: The number of training samples (22) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:09<00:00, 10.47it/s]\n",
      "Restoring states from the checkpoint path at /home/fatemeh/projects/nlp-project/final/lr_find_temp_model_3ec934b5-82d1-49e8-9ad5-30d168560800.ckpt\n",
      "Learning rate set to 0.0022908676527677745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr_find': <pytorch_lightning.tuner.lr_finder._LRFinder at 0x7f21741dcdd8>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.tune(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7d0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
      "\n",
      "  | Name       | Type   | Params\n",
      "--------------------------------------\n",
      "0 | linear_inp | Linear | 30.2 K\n",
      "1 | gru        | GRU    | 121 K \n",
      "2 | linear_out | Linear | 903   \n",
      "--------------------------------------\n",
      "152 K     Trainable params\n",
      "0         Non-trainable params\n",
      "152 K     Total params\n",
      "0.609     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /home/fatemeh/projects/nlp-project/final/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 26/26 [00:04<00:00,  6.16it/s, loss=0.00343, v_num=2, val_precision=0.980, val_recall=0.980, val_accuracy=0.980, val_f1=0.980, val_loss=0.0949]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07020bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeKasreGruModel(\n",
       "  (linear_inp): Linear(in_features=301, out_features=100, bias=True)\n",
       "  (gru): GRU(100, 100, bidirectional=True)\n",
       "  (linear_out): Linear(in_features=300, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_from_checkpoint(model_checkpoint.best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76336477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:454: UserWarning: Your `test_dataloader` has `shuffle=True`,it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  f\"Your `{mode.dataloader_prefix}_dataloader` has `shuffle=True`,\"\n",
      "/home/fatemeh/.local/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:112: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 22/22 [00:00<00:00, 18.56it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.9998605847358704,\n",
      " 'test_f1': 0.9998605847358704,\n",
      " 'test_loss': 0.0034246868453919888,\n",
      " 'test_precision': 0.9998605847358704,\n",
      " 'test_recall': 0.9998605847358704}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 22/22 [00:00<00:00, 28.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_precision': 0.9998605847358704,\n",
       "  'test_recall': 0.9998605847358704,\n",
       "  'test_accuracy': 0.9998605847358704,\n",
       "  'test_f1': 0.9998605847358704,\n",
       "  'test_loss': 0.0034246868453919888}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, data_module.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6c01e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 4/4 [00:00<00:00, 10.07it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_accuracy': 0.9801323413848877,\n",
      " 'test_f1': 0.9801323413848877,\n",
      " 'test_loss': 0.09486888349056244,\n",
      " 'test_precision': 0.9801323413848877,\n",
      " 'test_recall': 0.9801323413848877}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 4/4 [00:00<00:00, 14.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_precision': 0.9801323413848877,\n",
       "  'test_recall': 0.9801323413848877,\n",
       "  'test_accuracy': 0.9801323413848877,\n",
       "  'test_f1': 0.9801323413848877,\n",
       "  'test_loss': 0.09486888349056244}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, data_module.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e76cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, text):\n",
    "    mapping = {0: 0, 1: -1, 2: 1}\n",
    "    return [\n",
    "        mapping[n.item()]\n",
    "        for n in (\n",
    "            model.inference(**data_module.extract_features(text)).argmax(-1).squeeze(-1)\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "733512e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_decoder(input_sentence, output_map):\n",
    "    output_sentence = []\n",
    "    i = 0\n",
    "    for value in output_map:\n",
    "        corresponding_word = input_sentence[i]\n",
    "        i += 1\n",
    "        if value == 1:\n",
    "            corresponding_word = corresponding_word[0:-1]\n",
    "        elif value == -1:\n",
    "            corresponding_word += \"ه\"\n",
    "        output_sentence.append(corresponding_word)\n",
    "    output_sentence = \" \".join(output_sentence)\n",
    "    return output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ff09b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"این کتاب ماله من نیست\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f288c32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'این کتاب مال من نیست'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence = text.split()\n",
    "output_map = inference(model, input_sentence)\n",
    "output_decoder(input_sentence, output_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
